[["index.html", "Ingredientes e Receitas de bolo Chapter 1 Ingredientes 1.1 Análise exploratória 1.2 Medidas de tendência central", " Ingredientes e Receitas de bolo LAC-FMB 16/10/20 Chapter 1 Ingredientes Coleção de referência com procedimentos estatísticos frequentemente usados. A sessão Ingredientes contém uma coleção de funções selecionadas de diversos pacotes disponíveis. A sessão Kata contém sequências de análise usando as ferramentas diversas ao longo de um racional de análise. 1.1 Análise exploratória 1.1.1 Fundamentos teóricos É importante entender os tipos das variáveis consideradas, assim como a distribuição probabilística de origem. 1.1.1.1 NOTA Reescrever as sessões abaixo. 1.1.1.2 Mínima entropia, Teorema do Limite Central e Curva Normal Postulado inicialmente pelo matemático francês Abraham de Moivre, o teorema conclui que uma série de dados que não possui comportamento semelhantes à uma distribuição probabilística normal, quando adicionados mais dados referente ao mesmo evento, sua curva de distribuição probabilística irá tender a assemelhar-se com uma distribuição normal. 1.1.1.3 Distribuição probabilística normal A distribuição probabilística normal, também conhecida como distribuição de gaussiana, é uma das distribuições matemáticas de probabilidade. É caracterizada por ser parametrizada, possuir dados contínuos, concentração dos valores em torno da média, um desvio padrão (que caracteriza a distância média dos dados à média), simetria em torno do valor central e baixa frequência de valores extremos. 1.1.1.4 Gramática de gráficos 1.2 Medidas de tendência central As medidas de tendência central se referem a formas de definir um valor central dentro de uma distribuição probabilística, elas podem ser uma média, mediana ou moda. A média é a forma mais utilizada, ela representa um ponto que minimiza a distância total em relação a outros pontos. 1.2.0.1 1.2.3.1.Média 1.2.0.1.1 1.2.3.1.1.Média simples Função: mean(x, na.rm = T/F) x é a variável de entrada na.rm é utilizado para remover entradas com valores faltando. 1.2.0.1.2 1.2.3.1.2.Média entre variáveis Função: tapply(x, index, mean) x é a variável a ser tirada a média. index é a variável de categorização. mean é a função de média. 1.2.0.2 1.2.3.2.Mediana 1.2.0.2.1 1.2.3.2.1.Mediana simples Função: median(x, na.rm = T/F) x é a variável de entrada. na.rm é utilizado para remover entradas com valores faltando. 1.2.0.2.2 1.2.3.2.2.Mediana entre variáveis Função: tapply(x, index, median) x é a variável a ser tirada a mediana. index é a variável de categorização. mean é a função de mediana. 1.2.0.3 1.2.3.3.Moda 1.2.0.3.1 1.2.3.3.1.Moda simples No R puro não existe a função moda, então uma opção é criar uma função que avalie os valores, e identifique o de maior ocorrência. Função: y &lt;- BD$age moda &lt;- function(y, na.rm = T/F) { if(na.rm){ y = y[!is.na(y)] } uy &lt;- unique(y) tab &lt;- tabulate(match(y, uy)) uy[tab == max(tab)] } moda(y) x é a variável de entrada na.rm é utilizado para remover entradas com valores faltando. Outra opção é instalar bibliotecas que contenham ferramentas semelhantes.A modeest é uma opção. Vamos instalá-la e carregá-la: library(modeest) mfv(x) x é a variável de entrada 1.2.0.3.2 #3.3.2.Moda entre variáveis Função: tapply(x, index, mfv(x)) x é a variável a ser tirada a moda. index é a variável de categorização. mean é a função de moda, podendo ser tanto a “moda” quanto a “mfv”. 1.2.1 Dispersão É forma de caracterizar um conjunto de dados quanto ao seu comportamento aleatório de dispersão de valores. Existem vários modelos de caracterizar o quão disperso um conjunto de dados está, incluindo desvio padrão, coeficiente de variação, coeficiente de dispersão quartil, entre outros. 1.2.2 Assimetria Skewness 1.2.3 1.2.4.Gráficos 1.2.3.1 1.2.4.1.Correlação 1.2.3.1.1 1.2.4.1.1.Preditores contínuos Função: scatter.smooth(x,y,main=&quot;&quot;,xlab=&quot;&quot;,ylab=&quot;&quot;) x é o preditor 1, na abscissa y é o preditor 2, na ordenada main é o título do gráfico xlab é o título da abscissa ylab é o título da ordenada 1.2.3.1.2 1.2.4.1.2.Preditores categóricos Função: boxplot(y ~ x, data = k, main=&quot;Title&quot;, xlab=&quot;x Title&quot;, ylab=&quot;y Title&quot;) x é o preditor 1, na abscissa y é o preditor 2, na ordenada main é o título do gráfico xlab é o título da abscissa ylab é o título da ordenada OBS: é possível identificar no boxplot os limites, outliers, terceiro, segundo (mediana) e primeiro quartis. 1.2.3.2 1.2.4.2.Histogramas Função: BD &lt;- readxl::read_excel(&quot;data/lbw.xlsx&quot;) # Requer lib reaxl hist(BD$age, main = &quot;Title&quot;, xlab = &quot;Title&quot;, ylab = &quot;Title&quot;, prob = T) rug(jitter(BD$age))#;lines( density(x),col=&quot;red&quot; ) x é a variável de interesse main é o título do gráfico xlab é o título da abscissa (Variável) ylab é o título da ordenada (Frequência) Breaks são pontos de divisão de cada coluna, na abscissa rug/jitter mostra a distribuição fina de frequência, na abscissa 1.2.4 1.2.5.Exercícios 1.2.4.1 1.2.5.1.Qual a idade materna média no grupo de fumantes e não fumantes? tapply(BD$age, BD$smoke, mean) ## 0 1 ## 23.42609 22.94595 1.2.4.2 1.2.5.2.Plote o gráfico da distribuição das idades maternas analisadas hist(BD$age, main = &quot;Title&quot;, xlab = &quot;Title&quot;, ylab = &quot;Title&quot;, prob = T) rug(jitter(BD$age));lines( density(BD$age),col=&quot;red&quot; ) #### 1.2.5.3.Qual a mediana do peso materno entre as raças? tapply(BD$lwt, BD$race, median) ## 1 2 3 ## 129.5 129.0 119.0 1.2.4.3 1.2.5.4.Qual a moda da idade materna entre os grupos com e sem hipertensão? library(modeest) tapply(BD$age, BD$ht, mfv) ## $`0` ## [1] 20 ## ## $`1` ## [1] 19 21 22 25 1.2.4.4 1.2.5.5.Plote o gráfico da correlação entre o peso materno e o peso ao nascer scatter.smooth(BD$lwt,BD$bwt,main=&quot;&quot;,xlab=&quot;&quot;,ylab=&quot;&quot;) "],["teste-de-hipóteses.html", "Chapter 2 Teste de Hipóteses 2.1 Associações 2.2 Análise multivariada 2.3 Inferência Bayesiana", " Chapter 2 Teste de Hipóteses 2.0.1 2.1.1.Baixar e Instalar Bibliotecas Para esta aula utilizaremos apenas* funções nativas do R, sem necessidade de instalar ou carregar bibliotecas adicionais. 2.0.2 2.1.2.Banco de dados e variaveis 2.0.2.1 2.1.2.1.Ler o banco de dados em excel BD &lt;- readxl::read_excel(&quot;data/lbw.xlsx&quot;) 2.0.2.2 2.1.2.2.Visualizar o banco de dados no RStudio View(BD) 2.0.2.3 2.1.2.3.Ajustar o BD para as classes das variáveis BD[,c(&quot;low&quot;,&quot;race&quot;,&quot;smoke&quot;,&quot;ptl&quot;,&quot;ht&quot;,&quot;ui&quot;,&quot;ftv&quot;)] &lt;- lapply(BD[,c(&quot;low&quot;,&quot;race&quot;,&quot;smoke&quot;,&quot;ptl&quot;,&quot;ht&quot;,&quot;ui&quot;,&quot;ftv&quot;)], as.factor) BD$low &lt;- factor(BD$low, levels = c(0,1), labels = c(&quot;Não&quot;, &quot;Sim&quot;)) BD &lt;- transform(BD, lwt=round(lwt*0.453592,1)) BD$race &lt;- factor(BD$race, levels = c(1,2,3), labels = c(&quot;Branca&quot;, &quot;Negra&quot;,&quot;Outra&quot;)) BD$smoke &lt;- factor(BD$smoke, levels = c(0,1), labels = c(&quot;Não&quot;, &quot;Sim&quot;)) BD$ht &lt;- factor(BD$ht, levels = c(0,1), labels = c(&quot;Não&quot;, &quot;Sim&quot;)) BD$ui &lt;- factor(BD$ui, levels = c(0,1), labels = c(&quot;Não&quot;, &quot;Sim&quot;)) 2.0.2.4 2.1.2.4.Verificar as propriedades das variáveis (verifica dados como ocorrência, quartis, média, mediana, limites etc): summary(BD) ## id low age lwt race smoke ## Min. : 4.0 Não:130 Min. :14.00 Min. : 36.30 Branca:96 Não:115 ## 1st Qu.: 68.0 Sim: 59 1st Qu.:19.00 1st Qu.: 49.90 Negra :26 Sim: 74 ## Median :123.0 Median :23.00 Median : 54.90 Outra :67 ## Mean :121.1 Mean :23.24 Mean : 58.88 ## 3rd Qu.:176.0 3rd Qu.:26.00 3rd Qu.: 63.50 ## Max. :226.0 Max. :45.00 Max. :113.40 ## ptl ht ui ftv bwt ## 0:159 Não:177 Não:161 0:100 Min. : 709 ## 1: 24 Sim: 12 Sim: 28 1: 47 1st Qu.:2414 ## 2: 5 2: 30 Median :2977 ## 3: 1 3: 7 Mean :2945 ## 4: 4 3rd Qu.:3475 ## 6: 1 Max. :4990 (verificar existência de dados faltantes (NA) no banco de dados): NAs &lt;- is.na(BD);which(TRUE == NAs) ## integer(0) 2.0.3 2.1.3. Hipótese I Para o primeiro exemplo, vamos supor que estamos tentando investigar a relação do tabagismo na gravidez com o peso do bebê ao nascer. Hipótese nula: Não há diferença no peso ao nascer de bebês de mães fumantes em em comparação com o peso ao nascer de bebês de mães não fumantes. Hipótese alternativa: Há diferença no peso ao nascer de bebês de mães fumantes em em comparação com o peso ao nascer de bebês de mães não fumantes. Nesse caso, temos uma variável categórica dicotômica como independente e uma variável contínua como dependente. Qual seria a opção de teste paramétrico? E de teste não-paramétrico? 2.0.3.1 2.1.3.1. Pressupostos (Teste T) A utilização do Teste T depende de algumas condições. ##### Homocedasticidade A cada nível das variáveis previsoras, a variância do termo residual deve ser constante. Isso significa que os resíduos a cada nível dos previsores devem ter a mesma variância (homocedasticidade): quando as variâncias são desiguais diz-se que existe heterocedasticidade. ###### Teste de Levene Função: LeveneTest(dados\\(vardependente~dados\\)varindependente) Df: Degrees of Freedom F value: Quanto mais distante de 1, maior é a diferença detectada entre as variâncias. O valor de p informa quando essa diferença é significativa ou não. Pr(&gt;F): Valor de p para o teste de Levene em que a Ho é que as variâncias são iguais. library(car) leveneTest(BD$bwt~BD$smoke) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 1 1.371 0.2431 ## 187 2.0.3.1.1 2.1.3.2. Normalidade 2.0.3.1.1.1 Aspecto visual hist(BD$bwt) plot(density(BD$bwt), ylab=&#39;Densidade&#39;, xlab=&#39;Peso ao Nascer&#39;, main=&#39;&#39;) ###### Shapiro-wilk Função: Shapiro.test(dados$vardependente) W: Quanto mais próximo de 1, maior é a semelhança da curva estudada com a distribuição normal. O valor de p informa quando essa semelhança é significativa ou não. P-value: Valor de p para o teste SW em que a Ho é que não há diferença entre a distribuição estudada e uma distribuição normal. shapiro.test(BD$bwt) ## ## Shapiro-Wilk normality test ## ## data: BD$bwt ## W = 0.99244, p-value = 0.4346 2.0.3.1.1.2 Kolmogorov-Smirnov Função: Ks.test(dados\\(vardependente,&quot;pnorm&quot;, mean(dados\\)vardependente), sd(dados$vardependente)) pnorm identifica que o KS vai comparar a distribuição da variável dependente com a normal D: Representa a distância vertical máxima entre a curva estudada e a curva de referência. Quando mais próximo de zero, maior a semelhança entre as duas distribuições. P-value: Valor de p para o teste KS em que a Ho é que não há diferença entre a distribuição estudada e uma distribuição normal. library(dgof) ks.test(BD$bwt,&quot;pnorm&quot;,mean(BD$bwt),sd(BD$bwt)) ## Warning in ks.test(BD$bwt, &quot;pnorm&quot;, mean(BD$bwt), sd(BD$bwt)): default ks.test() cannot compute correct p-values with ties; ## see help page for one-sample Kolmogorov test for discrete distributions. ## ## One-sample Kolmogorov-Smirnov test ## ## data: BD$bwt ## D = 0.043521, p-value = 0.8665 ## alternative hypothesis: two-sided 2.0.3.1.2 2.1.3.3. Teste de hipótese - T não pareado Função: t.test(dados\\(varindependente~BD\\)vardependente) t: A diferença calculada entre as médias em unidades de desvio padrão; Df: Degrees of freedom; P-value: Valor de p para o teste KS em que a Ho é que não há diferença entre as médias dos dois grupos. t.test(BD$bwt~BD$smoke) ## ## Welch Two Sample t-test ## ## data: BD$bwt by BD$smoke ## t = 2.7065, df = 169.97, p-value = 0.007494 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 76.16628 486.71973 ## sample estimates: ## mean in group Não mean in group Sim ## 3054.957 2773.514 2.0.4 2.1.4. Hipótese II Para o segundo exemplo, vamos supor que estamos tentando investigar a relação da raça da mãe com o peso ao nascer. Hipótese nula: Não há diferença no peso ao nascer de bebês de segundo a raça de suas mães. Hipótese alternativa: Há diferença no peso ao nascer de bebês de segundo a raça de suas mães. Nesse caso, temos uma variável categórica policotômica como independente e uma variável contínua como dependente. Quais seriam as opções para testes paramétricos e não-paramétricos? 2.0.4.1 2.1.4.1 Pressupostos (One-way ANOVA) 2.0.4.1.1 Homocedasticidade leveneTest(BD$bwt~BD$race) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 2 0.4588 0.6327 ## 186 2.0.4.1.2 2.1.4.2. Normalidade 2.0.4.1.2.1 Aspecto visual Distribuição da variável independente hist(BD$bwt) plot(density(BD$bwt), ylab=&#39;Densidade&#39;, xlab=&#39;Peso ao Nascer&#39;, main=&#39;&#39;) Variável independente x variável dependente plot(BD$bwt~BD$race, ylab =&#39;Peso ao nascer&#39;, xlab=&#39;Raça&#39;, main=&#39;&#39;) ###### Shapiro-wilk shapiro.test(BD$bwt) ## ## Shapiro-Wilk normality test ## ## data: BD$bwt ## W = 0.99244, p-value = 0.4346 ks.test(BD$bwt,&quot;pnorm&quot;,mean(BD$bwt),sd(BD$bwt)) ## Warning in ks.test(BD$bwt, &quot;pnorm&quot;, mean(BD$bwt), sd(BD$bwt)): default ks.test() cannot compute correct p-values with ties; ## see help page for one-sample Kolmogorov test for discrete distributions. ## ## One-sample Kolmogorov-Smirnov test ## ## data: BD$bwt ## D = 0.043521, p-value = 0.8665 ## alternative hypothesis: two-sided 2.0.4.1.3 2.1.4.3. Teste de hipótese - One-way ANOVA 2.0.4.1.3.1 Opção I - Função lm() Função: summary(lm(BD$bwt~BD$race)) ## ## Call: ## lm(formula = BD$bwt ~ BD$race) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2095.01 -503.01 -13.95 526.99 1886.05 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3103.95 72.88 42.588 &lt; 2e-16 *** ## BD$raceNegra -384.26 157.88 -2.434 0.01588 * ## BD$raceOutra -299.93 113.68 -2.638 0.00904 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 714.1 on 186 degrees of freedom ## Multiple R-squared: 0.05081, Adjusted R-squared: 0.0406 ## F-statistic: 4.978 on 2 and 186 DF, p-value: 0.007834 A função lm() é utilizada para construir modelos lineares de regressão. Sintaxe: lm(formula, data, weights, subset, na.action) A função summary() fornece os principais parâmetros do objeto. Retorno: Em termos de ANOVA, a parte de interesse do retorno é o F-statistic, que dá informação do F-value, dos DFs e p-value para a Ho de que todos os grupos têm médias iguais entre si. 2.0.4.1.3.2 Opção II - Função anova() Função: anova(lm(BD$bwt~BD$race)) ## Analysis of Variance Table ## ## Response: BD$bwt ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## BD$race 2 5076973 2538487 4.9779 0.007834 ** ## Residuals 186 94850291 509948 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 A função anova() é utilizada para construir uma tabela ANOVA do objeto fornaecido. Sintaxe: Anova(mod, …) em que mod pode ser lm para a “linear model”, aov para “análise de variância” e outras funções. Retorno: Informa Df, Sum sq, Mean Sq, F-value e p-value para a Ho de que todos os grupos têm médias iguais entre si. 2.0.4.1.4 Teste post-hoc (teste de Tuckey) Função: TukeyHSD(aov(BD$bwt~BD$race)) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = BD$bwt ~ BD$race) ## ## $`BD$race` ## diff lwr upr p adj ## Negra-Branca -384.25561 -757.2617 -11.24948 0.0418269 ## Outra-Branca -299.93299 -568.5164 -31.34961 0.0244102 ## Outra-Negra 84.32262 -305.5078 474.15306 0.8660602 A função TukeyHSD() realiza o teste de Tukey no mod especificado (no caso, aov). Sintaxe: TukeyHSD(x, which, ordered = FALSE, conf.level = 0.95, …) Retorno: O elemento de maior interesse vai ser o p-value para identificar os grupos nos quais as diferenças são analisadas. 2.0.5 2.1.5. Hipótese III Para o último exemplo, vamos supor que estamos tentando investigar a relação do peso da mãe no último ciclo menstrual com o hábito de fumar. Hipótese nula: Não há diferença significativa no peso da mãe no último ciclo menstrual entre entre os grupos de mães fumantes e não fumantes. Hipótese alternativa: Há diferença significativa no peso da mãe no último ciclo menstrual entre entre os grupos de mães fumantes e não fumantes. Nesse caso, temos uma variável categórica dicotômica como independente e uma variável contínua como dependente. Quais são algumas das opções teste de hipótese que podemos usar? 2.0.5.1 2.1.5.1 Pressupostos (One-way ANOVA) 2.0.5.1.1 Homocedasticidade leveneTest(BD$lwt~BD$smoke) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 1 0.5549 0.4572 ## 187 2.0.5.1.2 2.1.5.2. Normalidade 2.0.5.1.2.1 Aspecto visual Distribuição da variável independente hist(BD$lwt) plot(density(BD$lwt), ylab=&#39;Densidade&#39;, xlab=&#39;Peso da mãe no último ciclo menstrual&#39;, main=&#39;&#39;) ###### Shapiro-wilk shapiro.test(BD$lwt) ## ## Shapiro-Wilk normality test ## ## data: BD$lwt ## W = 0.89324, p-value = 2.219e-10 ks.test(BD$lwt,&quot;pnorm&quot;,mean(BD$lwt),sd(BD$lwt)) ## Warning in ks.test(BD$lwt, &quot;pnorm&quot;, mean(BD$lwt), sd(BD$lwt)): default ks.test() cannot compute correct p-values with ties; ## see help page for one-sample Kolmogorov test for discrete distributions. ## ## One-sample Kolmogorov-Smirnov test ## ## data: BD$lwt ## D = 0.15327, p-value = 0.0002782 ## alternative hypothesis: two-sided Aqui temos que o pressuposto da normalidade não é atendido. Precisamos recorrer a um teste não paramétrico. O teste de Teste de Wilcoxon-Mann-Whitney é uma opção quando o pressuposto da normalidade não é atendido. 2.0.5.1.3 2.1.5.3. Teste de hipótese - Wilcoxon-Mann-Whitney wilcox.test(BD$lwt~BD$smoke) ## ## Wilcoxon rank sum test with continuity correction ## ## data: BD$lwt by BD$smoke ## W = 4684, p-value = 0.2427 ## alternative hypothesis: true location shift is not equal to 0 Valor de p para o teste WMW em que a Ho é que não há diferença entre as médias dos dois grupos. 2.1 Associações 2.1.1 Correlações Lineares 2.1.1.1 O que são: Verificação de relação entre duas variáveis (se alterações em uma variável gera alterção em outra) OBS: um ponto é formado por duas coordenadas (X, Y) A correlação pode ser positiva ou negativa -&gt; se +, quando x aumenta, y aumenta Erros aleatórios existem porque NÃO conhecemos todas as variáveis 2.1.1.2 Quando são utilizadas: Quando objetiva-se correlacionar duas variáveis contínuas 2.1.1.3 3.1.3.3.Tipos: 2.1.1.3.1 PEARSON a - versão paramétrica (baseado nos desvios em relação à média) b - variáveis preditora deve ser contínua normal c - variável desfecho deve ser contínua normal 2.1.1.3.2 SPEARMAN a - versão não-paramétrica (Pearson aplicado aos ranks) b - variável preditora deve ser contínua c - variável desfecho deve ser contínua 2.1.1.4 3.1.3.4.Correlação de Pearson no R: 2.1.1.4.1 Comando cor.test(x,y, method = &quot;pearson&quot;) 2.1.1.4.2 Inputs # x -&gt; variável preditora # y -&gt; desfecho 2.1.1.4.3 Otputs #cor -&gt; índice de correlação -&gt; pode ir de -1 a + 1 #intervalo de confiança #p-value 2.1.1.4.4 Exemplo prático Teste de normalidade shapiro.test(BD$age) #não normal ## ## Shapiro-Wilk normality test ## ## data: BD$age ## W = 0.95977, p-value = 3.189e-05 qqnorm(BD$age);qqline(BD$age) hist(BD$age) shapiro.test(BD$lwt) #não normal ## ## Shapiro-Wilk normality test ## ## data: BD$lwt ## W = 0.89324, p-value = 2.219e-10 qqnorm(BD$lwt);qqline(BD$lwt) hist(BD$lwt) shapiro.test(BD$bwt) #normal ## ## Shapiro-Wilk normality test ## ## data: BD$bwt ## W = 0.99244, p-value = 0.4346 qqnorm(BD$bwt);qqline(BD$bwt) hist(BD$bwt) Aplicando cor.test(BD$age, BD$bwt, method = &quot;pearson&quot;) ## ## Pearson&#39;s product-moment correlation ## ## data: BD$age and BD$bwt ## t = 1.2377, df = 187, p-value = 0.2174 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.05327129 0.22991649 ## sample estimates: ## cor ## 0.0901444 *Uso de BD$age apenas como exemplo, visto que esta variável não possui distribuição normal. 2.1.1.4.5 Visualização gráfica Faça um gráfico com os pontos library(ggplot2) ggplot(BD, aes(age, bwt)) + geom_point() Produza ggplot(BD, aes(age, bwt)) + geom_point() + geom_smooth(method = &quot;lm&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; 2.1.1.5 3.1.3.5.Correlação de Spearman no R: 2.1.1.5.1 Comando cor.test(x,y, method = &quot;spearman&quot;) 2.1.1.5.2 Inputs # x -&gt; variável preditora # y -&gt; desfecho 2.1.1.5.3 Otputs #cor #intervalo de confiança #p-value 2.1.1.5.4 Aplicando cor.test(BD$lwt, BD$bwt, method = &quot;spearman&quot;) ## Warning in cor.test.default(BD$lwt, BD$bwt, method = &quot;spearman&quot;): Cannot compute ## exact p-value with ties ## ## Spearman&#39;s rank correlation rho ## ## data: BD$lwt and BD$bwt ## S = 845420, p-value = 0.0005609 ## alternative hypothesis: true rho is not equal to 0 ## sample estimates: ## rho ## 0.2486359 Como tem empates, usar método de kendall cor.test(BD$lwt, BD$bwt, method = &quot;kendall&quot;) ## ## Kendall&#39;s rank correlation tau ## ## data: BD$lwt and BD$bwt ## z = 3.4211, p-value = 0.0006237 ## alternative hypothesis: true tau is not equal to 0 ## sample estimates: ## tau ## 0.1696574 2.1.1.5.5 Visualização gráfica Faça um gráfico com os pontos ggplot(BD, aes(lwt, bwt)) + geom_point() Produza ggplot(BD, aes(lwt, bwt)) + geom_point() + geom_smooth(method = &quot;lm&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; #### 3.1.3.6.O que representa o índice de correlação: O ÍNDICE DE CORRELAÇÃO representa a MAGNITUDE e o SENTIDO de uma relação. Se X aumenta 10%, quanto muda Y? Se índice de correlação = +1, Y aumenta 10% pela mudança de X Se índice de correlação = -1, Y diminui 10% pela mudança de X Se índice de correlação = 0, Y não muda pela mudança de X cor(BD$age, BD$bwt, use = &quot;complete.obs&quot;) #sem executar teste estátistico ## [1] 0.0901444 2.1.1.6 3.1.3.6.O que representa o valor de p: Mensurar o quão improváveis são as observações em um cenário hipotético na vigência da hipótese nula (ARGOLO, 2020) - dada a hipótese nula de que o índice de correlação = 0 e que a hipótese alternativa de que o índice de correlação é diferente de 0. 2.1.2 3.1.4.Regressões 2.1.2.1 3.1.4.1.O que são: ??????????? #### 3.1.4.2.Quando são utilizadas: Busca-se saber magnitude das causas para o efeito (causalidade) para PREDIZER “advinhar uma medida com base na outra” ARGOLO, F. 2020 #### 3.1.3.3.Tipos: ##### Linear a - variável preditora contínua, categórica dicotômica, categórica policotômica b - variável desfecho contínua c - 5 pressupostos: 1. Independência 2. Normalidade dos resíduos 2. Homocedasticidade - resíduos simétricos 3. Colinearidade - modelo melhor explicado por linear 5. Aditividade - efeito aditivo (modificadores de efeito) 2.1.2.1.1 Logística a - variável preditora contínua, categórica, etc b - variável desfecho categórica binária c - pressupostos: 1 - Colinearidade 2 - Independência 3 - Modificador de efeito 2.1.2.1.2 Outras Regressão mediana -&gt; não normal e contínua Regressão ordinal ligística -&gt; ordinal categórica Regressão multinominal -&gt; não-ordinal categórica Regressão de Poisson ou negativa binominal -&gt; números inteiros Regressão de Cox -&gt; tempo até o evento 2.1.2.2 3.1.4.4.Regressão Linear no R: 2.1.2.2.1 Comando nome &lt;- lm (y ~ x1 + x2 + x3, data = a) 2.1.2.2.2 Inputs x1, x2, x3 -&gt; variáveis preditoras y -&gt; desfecho contínuo a -&gt; banco de dados 2.1.2.2.3 Otputs Distribuição dos resíduos Coeficientes: a. Estimate = Beta b. Pr(&gt;|t|) = Valor de P Multiple R-squared -&gt; coeficiente de determinação -&gt; próximo a 1 indica resíduos próximos a 0 2.2 Análise multivariada 2.3 Inferência Bayesiana "],["kata.html", "Chapter 3 Kata 3.1 Kata - Avaliar distribuição Open data OSF", " Chapter 3 Kata 3.1 Kata - Avaliar distribuição Open data OSF https://osf.io/3bhuk/ Material suplementar do relato “Relações entre Acesso Aberto, QUALIS CAPES e desempenho de citação (Índices h, e, AW e hl Anual) em periódicos científicos brasileiros de Ciência da Informação – estudo documental exploratório”, publicado na Informação &amp; Sociedade: Estudos, 30(1), 2020 3.1.1 Objetivo Usar o dataset disponibilizado para verificar inferências secundárias do artigo. 3.1.2 Bibliotecas e dados library(ggplot2) library(gridExtra) # multiplos plots # library(readxl) é usada pontualmente infoj_df &lt;- readxl::read_excel(&quot;Dataset API Google.xlsx&quot;) infoj_df$Authors_Paper &lt;- as.numeric(infoj_df$Authors_Paper) 3.1.3 Análise exploratória Analisamos a distribuição de citações, número de artigos, e número de autores por artigo. O tamanho amostral dificulta bastante fazer inferências. Assumiremos distribuição gaussiana (princípio de máxima de entropia) ou usaremos soluções não paramétricas (sem distribuição de base). A densidade estimada para número de autores por artigo parece mais comportada. p_paperDist &lt;- ggplot(infoj_df,aes(x = Papers))+ geom_density(color=&quot;light green&quot;)+ geom_histogram(aes(y=stat(density)),position=&quot;dodge&quot;)+ theme_light() p_paperDistQualis &lt;- ggplot(infoj_df,aes(x = Papers,fill=QUALIS))+ geom_density(color=&quot;light green&quot;)+ geom_histogram(aes(y=stat(density)),position=&quot;dodge&quot;)+ theme_light() p_citDist &lt;- ggplot(infoj_df,aes(x = Citations))+ geom_density(color=&quot;light blue&quot;)+ geom_histogram(aes(y=stat(density)),position=&quot;dodge&quot;)+ theme_light() p_citDistQualis &lt;- ggplot(infoj_df,aes(x = Citations,fill=QUALIS))+ geom_density(color=&quot;light blue&quot;)+ geom_histogram(aes(y=stat(density)),position=&quot;dodge&quot;)+ theme_light() p_citDist &lt;- ggplot(infoj_df,aes(x = Citations))+ geom_density(color=&quot;light blue&quot;)+ geom_histogram(aes(y=stat(density)),position=&quot;dodge&quot;)+ theme_light() p_autpapersDist &lt;- ggplot(infoj_df,aes(x = Authors_Paper))+ geom_density(color=&quot;light blue&quot;)+ geom_histogram(aes(y=stat(density)),position=&quot;dodge&quot;)+ theme_light() p_autpapersDistQualis &lt;- ggplot(infoj_df,aes(x = Authors_Paper,fill=QUALIS))+ geom_density(color=&quot;light blue&quot;)+ geom_histogram(aes(y=stat(density)),position=&quot;dodge&quot;)+ theme_light() gridExtra::grid.arrange(p_citDist,p_citDistQualis, p_paperDist,p_paperDistQualis, p_autpapersDist,p_autpapersDistQualis, layout_matrix = rbind(c(1, 2),c(3, 4),c(5,6))) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Examinamos a associação entre (1) Citações e artigo e entre (2) Citações e Número de autores por artigo. p_paperscit &lt;- ggplot(infoj_df,aes(x = Papers,y=Citations))+ geom_point(aes(color=QUALIS))+ theme_light()+geom_smooth(method=&quot;lm&quot;) p_authorscit &lt;- ggplot(infoj_df,aes(x = Authors_Paper,y=Citations))+ geom_point(aes(color=QUALIS))+theme_light()+ geom_smooth(aes(x = Authors_Paper,y=Citations),method=&quot;lm&quot;) gridExtra::grid.arrange(p_paperscit,p_authorscit) ## `geom_smooth()` using formula &#39;y ~ x&#39; ## `geom_smooth()` using formula &#39;y ~ x&#39; "]]
